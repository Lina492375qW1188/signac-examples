{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32c13ab-1793-4997-b040-eb61b1ec7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hoomd\n",
    "import gsd.hoomd\n",
    "import freud\n",
    "import coxeter\n",
    "\n",
    "from simulation import init, randomize\n",
    "\n",
    "from verts_lib import octa, hexbp, trunc_octa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8ed4b5-6a1c-4287-b3a2-048504b33a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of fixed parameter\n",
    "N_particles_arr = [1000]\n",
    "vertices_arr = [hexbp]\n",
    "particle = coxeter.shapes.ConvexPolyhedron( vertices_arr[0] )\n",
    "particle_volume_arr = [particle.volume]\n",
    "pressure_arr = [12., 14.]\n",
    "\n",
    "# List to explore\n",
    "seed_arr = [i for i in range(1,3)]\n",
    "inertia_arr = []\n",
    "for ri in np.array([1.]):\n",
    "    diag_inertia = particle.inertia_tensor.diagonal().copy()\n",
    "    diag_inertia[2] *= ri\n",
    "    inertia_arr.append(diag_inertia)\n",
    "    \n",
    "sp_dict = list(itertools.product(N_particles_arr, \n",
    "                                 vertices_arr, \n",
    "                                 particle_volume_arr, \n",
    "                                 pressure_arr, \n",
    "                                 seed_arr, \n",
    "                                 inertia_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6014234-e1f0-41a6-8041-11cb6653f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobDict(dict):\n",
    "    \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "\n",
    "class Job:\n",
    "    \n",
    "    def __init__(self, job_id, job_path, statepoint):\n",
    "    \n",
    "        self.job_id = job_id\n",
    "        self.job_path = job_path\n",
    "        \n",
    "        self.statepoint_path = os.path.join(self.job_path, 'statepoint.npy')\n",
    "        self.document_path = os.path.join(self.job_path, 'document.npy')\n",
    "        \n",
    "        if os.path.exists(self.statepoint_path):\n",
    "            statepoint = np.load(self.statepoint_path, allow_pickle=True).tolist()\n",
    "        \n",
    "        self.sp = JobDict(statepoint)\n",
    "        self.statepoint = self.sp\n",
    "        \n",
    "        if os.path.exists(self.document_path):\n",
    "            document = np.load(self.document_path, allow_pickle=True).tolist()\n",
    "        else:\n",
    "            document = {}\n",
    "            \n",
    "        self.doc = JobDict(document)\n",
    "        self.document = self.doc\n",
    "        \n",
    "        \n",
    "    def init(self):\n",
    "        \n",
    "        if not os.path.isdir(self.job_path):\n",
    "            os.makedirs(self.job_path)\n",
    "        \n",
    "        if not os.path.exists(self.statepoint_path):\n",
    "            np.save(self.statepoint_path, dict(self.sp))\n",
    "        else:\n",
    "            print('job already exist!')\n",
    "            \n",
    "    def fn(self, filename):\n",
    "        \n",
    "        job_associated_path = os.path.join(self.job_path, filename)\n",
    "        \n",
    "        return job_associated_path\n",
    "    \n",
    "    def update(self):\n",
    "        \n",
    "        np.save(self.statepoint_path, dict(self.sp))\n",
    "        np.save(self.document_path, dict(self.doc))\n",
    "    \n",
    "        \n",
    "class Project:\n",
    "\n",
    "    def __init__(self, project_name='project'):\n",
    "        \n",
    "        self.project_name = project_name\n",
    "        self.project_path = self.project_name\n",
    "        self.job_id = -1\n",
    "        \n",
    "        self.id2sp = {}\n",
    "        self.id2job_path = {}\n",
    "        \n",
    "        if not os.path.isdir(self.project_path):\n",
    "            os.makedirs(self.project_path)\n",
    "            \n",
    "    def open_job(self, statepoint):\n",
    "        \"\"\"\n",
    "        Open a new job without overwriting existing jobs.\n",
    "        \"\"\"\n",
    "        self.job_id += 1\n",
    "        job_path = os.path.join(self.project_path, '{:06d}'.format(self.job_id))\n",
    "        if not os.path.isdir(job_path):\n",
    "            \n",
    "            self.id2sp[self.job_id] = statepoint\n",
    "            self.id2job_path[self.job_id] = job_path\n",
    "            \n",
    "            return Job(self.job_id, job_path, statepoint)\n",
    "        \n",
    "        else:\n",
    "            if not self.id2sp or self.id2job_path: \n",
    "                self.get_jobs() # run only once\n",
    "            statepoint_i = self.id2sp[self.job_id]\n",
    "            job_path_i = self.id2job_path[self.job_id]\n",
    "            \n",
    "            return Job(self.job_id, job_path_i, statepoint_i)\n",
    "        \n",
    "    def get_jobs(self):\n",
    "        \"\"\"\n",
    "        Get jobs in the project folder.\n",
    "        \"\"\"\n",
    "        for job_id_i in os.listdir(self.project_name):\n",
    "            \n",
    "            i = int(job_id_i)\n",
    "            job_path_i = os.path.join(self.project_name, job_id_i)\n",
    "            statepoint_path_i = os.path.join(job_path_i, 'statepoint.npy')\n",
    "            statepoint_i = np.load(statepoint_path_i, allow_pickle=True).tolist()\n",
    "            \n",
    "            self.id2sp[i] = statepoint_i\n",
    "            self.id2job_path[i] = job_path_i\n",
    "        \n",
    "    def find_jobs(self, condition=None):\n",
    "        \"\"\"\n",
    "        Find jobs which match the condition.\n",
    "        \"\"\"\n",
    "        if condition==None:\n",
    "            for job_id_i, job_path_i in self.id2job_path.items():\n",
    "                statepoint_i = self.id2sp[job_id_i]\n",
    "                yield Job(job_id_i, job_path_i, statepoint_i)\n",
    "        \n",
    "        else:\n",
    "            for job_id_i, statepoint_i in self.id2sp.items():\n",
    "                if all(statepoint_i[k] == v for k, v in condition.items()):\n",
    "                    job_path_i = self.id2job_path[job_id_i]\n",
    "                    yield Job(job_id_i, job_path_i, statepoint_i)\n",
    "            \n",
    "    def find_job_ids(self, job_id_arr):\n",
    "        \"\"\"\n",
    "        Find jobs which match the job_id.\n",
    "        \"\"\"\n",
    "        for job_id_i in job_id_arr:\n",
    "            job_path_i = self.id2job_path[job_id_i]\n",
    "            statepoint_i = self.id2sp[job_id_i]\n",
    "            yield Job(job_id_i, job_path_i, statepoint_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100c71b1-596e-4ba5-b686-69cf18cb874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Project('test_project')\n",
    "project.get_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558e0fb5-3e85-4195-9d54-992d8aa846d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_particles': 1000, 'vertices': array([[ 0.00000000e+00,  0.00000000e+00,  1.12000000e+00],\n",
      "       [ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-1.00000000e+00,  1.22464680e-16,  0.00000000e+00],\n",
      "       [-5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00, -1.12000000e+00]]), 'particle_volume': 1.9398969044771421, 'pressure': 12.0, 'seed': 2, 'inertia': array([0.48582778, 0.48582778, 0.48497423]), 'new_var': 1}\n",
      "{'N_particles': 1000, 'vertices': array([[ 0.00000000e+00,  0.00000000e+00,  1.12000000e+00],\n",
      "       [ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-1.00000000e+00,  1.22464680e-16,  0.00000000e+00],\n",
      "       [-5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00, -1.12000000e+00]]), 'particle_volume': 1.9398969044771421, 'pressure': 14.0, 'seed': 1, 'inertia': array([0.48582778, 0.48582778, 0.48497423]), 'new_var': 1}\n",
      "{'N_particles': 1000, 'vertices': array([[ 0.00000000e+00,  0.00000000e+00,  1.12000000e+00],\n",
      "       [ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-1.00000000e+00,  1.22464680e-16,  0.00000000e+00],\n",
      "       [-5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00, -1.12000000e+00]]), 'particle_volume': 1.9398969044771421, 'pressure': 14.0, 'seed': 2, 'inertia': array([0.48582778, 0.48582778, 0.48497423]), 'new_var': 1}\n"
     ]
    }
   ],
   "source": [
    "for job in project.find_job_ids([1,2,3]):\n",
    "    \n",
    "    print(job.sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac290a-462b-4dc8-a07f-f4d2556b5963",
   "metadata": {},
   "source": [
    "#### Loading the project the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1032a96-870a-40c0-8b85-63cc205a36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Project('test_project')\n",
    "\n",
    "for N_particles, vertices, particle_volume, pressure, seed, inertia in sp_dict:\n",
    "    statepoint = dict(N_particles=N_particles, \n",
    "                      vertices=vertices,\n",
    "                      particle_volume=particle_volume,\n",
    "                      pressure=pressure, \n",
    "                      seed=seed,\n",
    "                      inertia=inertia)\n",
    "\n",
    "    job = project.open_job(statepoint)\n",
    "    job.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b52157-c33f-4057-8637-c1da2217224d",
   "metadata": {},
   "source": [
    "#### Add a new variable to the statepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ae3a9f-2b44-40ed-b501-75f0b23ad578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for job in project.find_jobs():\n",
    "    job.sp.new_var=1\n",
    "    job.update()\n",
    "    \n",
    "for job in project.find_jobs():\n",
    "    print(job.sp.new_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f6ea4-20e5-4817-a72f-a5a21620bcb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Find jobs matching conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3107e32-4158-4125-9f8f-f8f60b812852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_particles': 1000, 'vertices': array([[ 0.00000000e+00,  0.00000000e+00,  1.12000000e+00],\n",
      "       [ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [ 5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-5.00000000e-01,  8.66025404e-01,  0.00000000e+00],\n",
      "       [-1.00000000e+00,  1.22464680e-16,  0.00000000e+00],\n",
      "       [-5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 5.00000000e-01, -8.66025404e-01,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00, -1.12000000e+00]]), 'particle_volume': 1.9398969044771421, 'pressure': 14.0, 'seed': 2, 'inertia': array([0.48582778, 0.48582778, 0.48497423]), 'new_var': 1}\n",
      "N_particles: 1000\n",
      "seed: 1\n",
      "pressure: 12.0\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "condition = {'N_particles': 1000, 'pressure': 12., 'seed': 1}\n",
    "\n",
    "for job_i in project.find_jobs(condition):\n",
    "    statepoint0 = np.load(job.fn('statepoint.npy'), allow_pickle=True).tolist()\n",
    "    print( statepoint0 )\n",
    "    print('N_particles:', job_i.sp.N_particles)\n",
    "    print('seed:', job_i.sp.seed)\n",
    "    print('pressure:', job_i.sp.pressure)\n",
    "    print('------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5e24f-b9e5-4e5f-b6b7-6f33ae8ec4cb",
   "metadata": {},
   "source": [
    "#### Find all jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29519ddb-cef0-4931-ad77-471836af823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_particles: 1000 | seed: 1 | pressure: 12.0\n",
      "N_particles: 1000 | seed: 2 | pressure: 12.0\n",
      "N_particles: 1000 | seed: 1 | pressure: 14.0\n",
      "N_particles: 1000 | seed: 2 | pressure: 14.0\n"
     ]
    }
   ],
   "source": [
    "for job_i in project.find_jobs():\n",
    "    \n",
    "    sp_load = np.load(job.fn('statepoint.npy'), allow_pickle=True)\n",
    "    \n",
    "    print('N_particles:', job_i.sp.N_particles, \n",
    "          '| seed:', job_i.sp.seed, \n",
    "          '| pressure:', job_i.sp.pressure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620e730-680f-4b88-9d5e-3df151d79da3",
   "metadata": {},
   "source": [
    "#### Add job document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65168e6-77f5-4ca6-8f62-ce6480c1f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in project.find_jobs():\n",
    "    \n",
    "    particle = coxeter.shapes.ConvexPolyhedron( job.sp.vertices )\n",
    "    job.doc['verts'] = particle.vertices.tolist() \n",
    "    job.doc['faces'] = particle.faces \n",
    "    job.doc['sigma'] = 2*particle.insphere_from_center.radius \n",
    "    job.doc['r_cut'] = 2*particle.circumsphere_from_center.radius + 0.15*job.doc.sigma\n",
    "    job.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4093dc40-d029-4979-87ce-391fae035168",
   "metadata": {},
   "source": [
    "#### Get existing project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e2d7595-d147-4bf8-b5d5-e8bc20bf8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Project('test_project')\n",
    "project.get_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0e417e-63fa-4937-b91e-752b9b719ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in project.find_jobs():\n",
    "    job.doc['init']=False\n",
    "    job.doc['randomize']=False\n",
    "    job.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49083372-a541-4164-bd94-fa942dbb9e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for job in project.find_jobs():\n",
    "    print(job.doc.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7215bedf-d288-4b59-a5a3-e878be07ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in project.find_jobs():\n",
    "    \n",
    "    if job.doc['init']==False:\n",
    "        init(job)\n",
    "    if job.doc['randomize']==False:\n",
    "        randomize(job)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
